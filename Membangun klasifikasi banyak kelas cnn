import sys
!{sys.executable} -m pip install tensorflow==2.3.0

import sys
!{sys.executable} -m pip install keras

import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense

import types
import pandas as pd
from botocore.client import Config
import ibm_boto3

def __iter__(self): return 0

# @hidden_cell
# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.
# You might want to remove those credentials before you share the notebook.
client_ef795513d32540c68ad0d8deee556ad6 = ibm_boto3.client(service_name='s3',
    ibm_api_key_id='XZsCzOZwoE98mEnBFENxvTbrZcSKzaYUjVfaTSdzDF8i',
    ibm_auth_endpoint="https://iam.cloud.ibm.com/oidc/token",
    config=Config(signature_version='oauth'),
    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')

body = client_ef795513d32540c68ad0d8deee556ad6.get_object(Bucket='latihan-donotdelete-pr-ord3wjrakgezze',Key='Iris.csv')['Body']
# add missing __iter__ method, so pandas accepts body as file-like object
if not hasattr(body, "__iter__"): body.__iter__ = types.MethodType( __iter__, body )

df= pd.read_csv(body)
df.head()

df = df.drop(columns='Id')

category = pd.get_dummies(df.Species)
category

new_df = pd.concat([df, category], axis=1)
new_df = new_df.drop(columns='Species')
new_df

dataset = new_df.values
dataset

# Pilih 4 kolom pertama untuk dijadikan sebagai atribut
X = dataset[:,0:4]
# Pilih 3 kolom terakhir sebagai label
y = dataset[:,4:7]

# Normalize
min_max_scaler = preprocessing.MinMaxScaler()
X_scale = min_max_scaler.fit_transform(X)
X_scale

X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)

model = Sequential([    
                    Dense(64, activation='relu', input_shape=(4,)),    
                    Dense(64, activation='relu'),    
                    Dense(3, activation='softmax'),])
                    
model.compile(optimizer='Adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
              
hist = model.fit(X_train, Y_train, epochs=100)

model.evaluate(X_test, Y_test)

model.predict([[5.1,3.5,1.4,0.2]])

# Melihat plot loss dan accuracy model
import matplotlib.pyplot as plt
# plot loss
plt.plot(hist.history['loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='upper right')
plt.show()

# plot accuracy 
plt.plot(hist.history['accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()
